{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb22483a-0aa4-44e4-87f5-d0aeaf83c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit\n",
    "\n",
    "from jax.experimental import mesh_utils, multihost_utils\n",
    "from jax.sharding import Mesh, PartitionSpec as P\n",
    "\n",
    "from function_diffusion.utils.data_utils import create_dataloader, BaseDataset\n",
    "from function_diffusion.utils.model_utils import (\n",
    "    create_optimizer,\n",
    "    create_autoencoder_state,\n",
    "    create_diffusion_state,\n",
    "    compute_total_params,\n",
    ")\n",
    "from function_diffusion.utils.train_utils import  sample_ode\n",
    "from function_diffusion.utils.checkpoint_utils import (\n",
    "    create_checkpoint_manager,\n",
    "    save_checkpoint,\n",
    "    restore_checkpoint,\n",
    ")\n",
    "\n",
    "from model import Encoder, Decoder, DiT\n",
    "from model_utils import create_encoder_step, create_decoder_step \n",
    "from data_utils import generate_dataset, BaseDataset, fit_damped_sine\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c76c993-fe48-4006-9bc0-acdab5a52ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import diffusion\n",
    "config = diffusion.get_config('fae,dit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99b25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_fae_state(config, encoder, decoder):\n",
    "    # Create learning rate schedule and optimizer\n",
    "    lr, tx = create_optimizer(config)\n",
    "\n",
    "    # Create train state\n",
    "    state = create_autoencoder_state(config, encoder, decoder, tx)\n",
    "\n",
    "    # Create checkpoint manager\n",
    "    fae_job_name = f\"{config.autoencoder.model_name}\" + f\"_{config.dataset.num_samples}_samples\"\n",
    "\n",
    "    ckpt_path = os.path.join(os.getcwd(), fae_job_name, \"ckpt\")\n",
    "    ckpt_mngr = create_checkpoint_manager(config.saving, ckpt_path)\n",
    "\n",
    "    # Restore the model from the checkpoint\n",
    "    fae_state = restore_checkpoint(ckpt_mngr, state)\n",
    "    print(f\"Restored model {fae_job_name} from step\", fae_state.step)\n",
    "\n",
    "    return fae_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize function autoencoder\n",
    "encoder = Encoder(**config.autoencoder.encoder)\n",
    "decoder = Decoder(**config.autoencoder.decoder)\n",
    "\n",
    "fae_state = restore_fae_state(config, encoder, decoder)\n",
    "\n",
    "# Initialize diffusion model\n",
    "dit = DiT(**config.diffusion)\n",
    "# Create learning rate schedule and optimizer\n",
    "lr, tx = create_optimizer(config)\n",
    "\n",
    "# Create diffusion train state\n",
    "state = create_diffusion_state(config, dit, tx)\n",
    "num_params = compute_total_params(state)\n",
    "print(f\"Model storage cost: {num_params * 4 / 1024 / 1024:.2f} MB of parameters\")\n",
    "\n",
    "# Device count\n",
    "num_local_devices = jax.local_device_count()\n",
    "num_devices = jax.device_count()\n",
    "print(f\"Number of devices: {num_devices}\")\n",
    "print(f\"Number of local devices: {num_local_devices}\")\n",
    "\n",
    "job_name = f\"{config.diffusion.model_name}\"\n",
    "job_name += f\"_{config.dataset.num_samples}_samples\"\n",
    "\n",
    "ckpt_path = os.path.join(os.getcwd(), job_name, \"ckpt\")\n",
    "# Create checkpoint manager\n",
    "ckpt_mngr = create_checkpoint_manager(config.saving, ckpt_path)\n",
    "\n",
    "# Restore the model from the checkpoint\n",
    "state = restore_checkpoint(ckpt_mngr, state)\n",
    "print(f\"Restored model {job_name} from step\", state.step)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create sharding for data parallelism\n",
    "mesh = Mesh(mesh_utils.create_device_mesh((jax.device_count(),)), \"batch\")\n",
    "state = multihost_utils.host_local_array_to_global_array(state, mesh, P())\n",
    "fae_state = multihost_utils.host_local_array_to_global_array(fae_state, mesh, P())\n",
    "\n",
    "# Create encoder and decoder steps\n",
    "encoder_step = create_encoder_step(encoder, mesh)\n",
    "decoder_step = create_decoder_step(decoder, mesh)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc678f0b2a9de71e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#  Generate samples\n",
    "coords = jnp.linspace(0, 1, 128)\n",
    "coords = multihost_utils.host_local_array_to_global_array(coords, mesh, P())\n",
    "\n",
    "x_test, y_test = generate_dataset(num_samples=8192, num_sensors=128)\n",
    "\n",
    "test_dataset = BaseDataset(x_test, y_test)\n",
    "test_loader = create_dataloader(test_dataset,\n",
    "                                batch_size=4096,\n",
    "                                num_workers=config.dataset.num_workers)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f92ac9e3a7eab9e6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(12345)\n",
    "\n",
    "u_pred_list = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    rng, keys = random.split(rng, 2)\n",
    "    batch = jax.tree.map(jnp.array, batch)\n",
    "    u = batch\n",
    "    u_batch = (jnp.ones_like(u), u, jnp.ones_like(u))\n",
    "\n",
    "    u_batch = multihost_utils.host_local_array_to_global_array(\n",
    "        u_batch, mesh, P(\"batch\")\n",
    "    )\n",
    "    z_u = encoder_step(fae_state.params[0], u_batch)\n",
    "\n",
    "    rng, subkey = random.split(keys)\n",
    "    z0 = random.normal(subkey, shape=z_u.shape)\n",
    "\n",
    "    z1_new, _ = sample_ode(state, z0=z0, num_steps=100)\n",
    "    u_pred = decoder_step(fae_state.params[1], z1_new, coords)\n",
    "\n",
    "    u_pred_list.append(u_pred)\n",
    "\n",
    "samples = jnp.concatenate(u_pred_list, axis=0)\n",
    "\n",
    "np.save(f\"samples_dit_{config.dataset.num_samples}_samples.npy\", samples)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44b2f57ecde11fb2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e51f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "def damped_sine(t, A, gamma, omega, shift):\n",
    "    return A * np.exp(-gamma * t) * np.sin(omega * t) + shift\n",
    "\n",
    "\n",
    "def fit_damped_sine_simple(t, y):\n",
    "    \"\"\"\n",
    "    Fit a damped sine using first two peaks and y[0] for shift.\n",
    "    \"\"\"\n",
    "    # Get shift directly from y[0]\n",
    "    shift = y[0]\n",
    "    y_no_shift = y - shift\n",
    "    \n",
    "    # Find peaks\n",
    "    peaks, _ = find_peaks(y_no_shift)\n",
    "    if len(peaks) < 2:\n",
    "        raise ValueError(\"Need at least two peaks to fit\")\n",
    "    \n",
    "    # Get first two peaks\n",
    "    t1, t2 = t[peaks[0]], t[peaks[1]]\n",
    "    y1, y2 = y_no_shift[peaks[0]], y_no_shift[peaks[1]]\n",
    "    \n",
    "    # Calculate parameters\n",
    "    omega = 2 * np.pi / (t2 - t1)\n",
    "    gamma = -np.log(abs(y2/y1)) / (t2 - t1)\n",
    "    A = y1 / np.exp(-gamma * t1)\n",
    "    \n",
    "    # Get uncertainties\n",
    "    y_fit = damped_sine(x, A, gamma, omega, shift)\n",
    "    mse = np.mean((y - y_fit)**2)\n",
    "\n",
    "    return {\n",
    "        \"A\": A,\n",
    "        \"gamma\": gamma,\n",
    "        \"omega\": omega,\n",
    "        \"shift\": shift,\n",
    "        \"mse\": mse\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1962ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Fit the data\n",
    "coords = jnp.linspace(0, 1, 128)\n",
    "\n",
    "num_samples = 1024\n",
    "generated_samples = np.load(f\"dit_samples_{num_samples}.npy\")\n",
    "\n",
    "# Visualize some samples\n",
    "k = 1\n",
    "x = coords\n",
    "y = generated_samples[k]\n",
    "\n",
    "# Get shift directly from y[0]\n",
    "shift = y[0]\n",
    "y_no_shift = y - shift\n",
    "\n",
    "# Find peaks\n",
    "peaks, _ = find_peaks(y_no_shift)\n",
    "if len(peaks) < 2:\n",
    "    raise ValueError(\"Need at least two peaks to fit\")\n",
    "\n",
    "# Get first two peaks\n",
    "x1, x2 = x[peaks[0]], x[peaks[1]]\n",
    "y1, y2 = y_no_shift[peaks[0]], y_no_shift[peaks[1]]\n",
    "\n",
    "# Calculate parameters\n",
    "omega = 2 * np.pi / (x2 - x1)\n",
    "gamma = -np.log(abs(y2/y1)) / (x2 - x1)\n",
    "A = y1 / np.exp(-gamma * x1)\n",
    "\n",
    "print(\"A:\", A, \"gamma:\", gamma, \"omega:\", omega, \"shift:\", shift)\n",
    "\n",
    "\n",
    "# Fit the data\n",
    "y_pred = damped_sine(x, A, gamma, omega, shift)\n",
    "plt.plot(x1, y1 + shift, 'ro')\n",
    "plt.plot(x2, y2 + shift, 'ro')\n",
    "plt.plot(x, y_pred, label='Fitted curve', linestyle='--')\n",
    "plt.plot(x, y, label='Generated data')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
