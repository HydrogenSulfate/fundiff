{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap\n",
    "\n",
    "from jax.experimental import mesh_utils, multihost_utils\n",
    "from jax.sharding import Mesh, PartitionSpec as P\n",
    "\n",
    "from function_diffusion.models import Encoder, Decoder, DiT\n",
    "\n",
    "from function_diffusion.utils.model_utils import (\n",
    "    create_autoencoder_state,\n",
    "    create_diffusion_state,\n",
    "    create_optimizer,\n",
    "    compute_total_params,\n",
    ")\n",
    "from function_diffusion.utils.train_utils import  sample_ode\n",
    "from function_diffusion.utils.data_utils import create_dataloader\n",
    "from function_diffusion.utils.checkpoint_utils import (\n",
    "    create_checkpoint_manager,\n",
    "    restore_checkpoint,\n",
    ")\n",
    "\n",
    "from model_utils import create_encoder_step, create_decoder_step\n",
    "from data_utils import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import diffusion\n",
    "\n",
    "config = diffusion.get_config('fae,dit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_fae_state(config, encoder, decoder):\n",
    "    # Create learning rate schedule and optimizer\n",
    "    lr, tx = create_optimizer(config)\n",
    "\n",
    "    # Create train state\n",
    "    state = create_autoencoder_state(config, encoder, decoder, tx)\n",
    "\n",
    "    # Create checkpoint manager\n",
    "    fae_job_name = f\"{config.autoencoder.model_name}_use_pde_{config.training.use_pde}\"\n",
    "\n",
    "    ckpt_path = os.path.join(os.getcwd(), fae_job_name, \"ckpt\")\n",
    "    ckpt_mngr = create_checkpoint_manager(config.saving, ckpt_path)\n",
    "\n",
    "    # Restore the model from the checkpoint\n",
    "    fae_state = restore_checkpoint(ckpt_mngr, state)\n",
    "    print(f\"Restored model {fae_job_name} from step\", fae_state.step)\n",
    "\n",
    "    return fae_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize function autoencoder\n",
    "encoder = Encoder(**config.autoencoder.encoder)\n",
    "decoder = Decoder(**config.autoencoder.decoder)\n",
    "\n",
    "fae_state = restore_fae_state(config, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize diffusion model\n",
    "dit = DiT(**config.diffusion)\n",
    "# Create learning rate schedule and optimizer\n",
    "lr, tx = create_optimizer(config)\n",
    "\n",
    "# Create diffusion train state\n",
    "state = create_diffusion_state(config, dit, tx, use_conditioning=True)\n",
    "num_params = compute_total_params(state)\n",
    "print(f\"Model storage cost: {num_params * 4 / 1024 / 1024:.2f} MB of parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint manager\n",
    "job_name = f\"{config.diffusion.model_name}_use_pde_{config.training.use_pde}\"\n",
    "ckpt_path = os.path.join(os.getcwd(), job_name, \"ckpt\")\n",
    "# Create checkpoint manager\n",
    "ckpt_mngr = create_checkpoint_manager(config.saving, ckpt_path)\n",
    "\n",
    "# Restore the model from the checkpoint\n",
    "state = restore_checkpoint(ckpt_mngr, state)\n",
    "print(f\"Restored model {job_name} from step\", state.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device count\n",
    "num_local_devices = jax.local_device_count()\n",
    "num_devices = jax.device_count()\n",
    "print(f\"Number of devices: {num_devices}\")\n",
    "print(f\"Number of local devices: {num_local_devices}\")\n",
    "\n",
    "# Create sharding for data parallelism\n",
    "mesh = Mesh(mesh_utils.create_device_mesh((jax.device_count(),)), \"batch\")\n",
    "state = multihost_utils.host_local_array_to_global_array(state, mesh, P())\n",
    "fae_state = multihost_utils.host_local_array_to_global_array(fae_state, mesh, P())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder and decoder steps\n",
    "encoder_step = create_encoder_step(encoder, mesh)\n",
    "decoder_step = create_decoder_step(decoder, mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test dataset\n",
    "_, test_dataset = create_dataset(config)\n",
    "test_loader = create_dataloader(test_dataset,\n",
    "                                batch_size=4,\n",
    "                                num_workers=config.dataset.num_workers,\n",
    "                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create uniform grid for evaluation\n",
    "h, w = 200, 200\n",
    "\n",
    "x_coords = jnp.linspace(0, 1, h)\n",
    "y_coords = jnp.linspace(0, 1, w)\n",
    "x_coords, y_coords = jnp.meshgrid(x_coords, y_coords, indexing='ij')\n",
    "coords = jnp.hstack([x_coords.reshape(-1, 1), y_coords.reshape(-1, 1)])\n",
    "coords = multihost_utils.host_local_array_to_global_array(coords, mesh, P())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = jax.random.PRNGKey(888)\n",
    "\n",
    "d = 5   # downsampling factor  # [1, 2, 5]\n",
    "noise_level = 0.2\n",
    "\n",
    "u_pred_list = []\n",
    "u_true_list = []\n",
    "r_pred_list = []\n",
    "u_downsampled_list = []\n",
    "\n",
    "iters = 0 \n",
    "for batch in tqdm(test_loader):\n",
    "    iters += 1\n",
    "\n",
    "    rng_key, *keys = random.split(rng_key, 3)\n",
    "    \n",
    "    batch = jax.tree.map(jnp.array, batch)\n",
    "\n",
    "    u = batch\n",
    "    u_downsammpled = batch[:, ::d, ::d]\n",
    "\n",
    "    noise = random.normal(keys[0], u_downsammpled.shape) * 0.2 * noise_level\n",
    "    u_downsammpled = u_downsammpled + noise\n",
    "\n",
    "    u_batch = (jnp.ones_like(u), u, jnp.ones_like(u))\n",
    "    c_batch = (jnp.ones_like(u_downsammpled), u_downsammpled, jnp.ones_like(u_downsammpled))\n",
    "\n",
    "    print(u_batch[0].shape, u_batch[1].shape, u_batch[2].shape)\n",
    "    print(c_batch[0].shape, c_batch[1].shape, c_batch[2].shape)\n",
    "\n",
    "    # # Shard the batch across devices\n",
    "    u_batch = multihost_utils.host_local_array_to_global_array(\n",
    "        u_batch, mesh, P(\"batch\")\n",
    "        )\n",
    "    c_batch = multihost_utils.host_local_array_to_global_array(\n",
    "        c_batch, mesh, P(\"batch\")\n",
    "        )\n",
    "\n",
    "    z_u = encoder_step(fae_state.params[0], u_batch)\n",
    "    z_c = encoder_step(fae_state.params[0], c_batch)\n",
    "\n",
    "    z0 = random.normal(keys[1], shape=z_u.shape)\n",
    "\n",
    "    z1_new, _ = sample_ode(state, z0=z0, c=z_c, num_steps=100, use_conditioning=True)  \n",
    "    u_pred, r_pred = decoder_step(fae_state.params[1], z1_new, coords)\n",
    "\n",
    "    u_pred = u_pred.reshape(-1, h, w)\n",
    "    u_true = u.reshape(-1, h, w)\n",
    "    r_pred = r_pred.reshape(-1, h, w)\n",
    "\n",
    "    u = u.reshape(-1, h, w)\n",
    "    u_downsammpled = u_downsammpled.reshape(-1, h//d, w//d)\n",
    "\n",
    "    u_pred_list.append(u_pred)\n",
    "    u_true_list.append(u)\n",
    "    r_pred_list.append(r_pred)\n",
    "    u_downsampled_list.append(u_downsammpled)\n",
    "\n",
    "    if iters ==4:\n",
    "        break\n",
    "\n",
    "u_pred = jnp.vstack(u_pred_list)\n",
    "u_true = jnp.vstack(u_true_list)\n",
    "r_pred = jnp.vstack(r_pred_list)\n",
    "u_downsammpled = jnp.vstack(u_downsampled_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(pred, y):\n",
    "    return jnp.linalg.norm(pred.flatten() - y.flatten()) / jnp.linalg.norm(y.flatten())\n",
    "\n",
    "error = vmap(compute_error)(u_pred, u_true)\n",
    "\n",
    "print(\"Mean relative error:\", jnp.mean(error))\n",
    "print(\"Max relative error:\", jnp.max(error))\n",
    "print(\"Min relative error:\", jnp.min(error))\n",
    "print(\"Std relative error:\", jnp.std(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of some examples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k = 0\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title('Input')\n",
    "plt.pcolor(u_downsammpled[k, :, :], cmap='jet')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title('Reference')\n",
    "plt.pcolor(u_true[k, :, :], cmap='jet')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title('Prediction')\n",
    "plt.pcolor(u_pred[k, :, :], cmap='jet')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title('Absolute Error')\n",
    "plt.pcolor(jnp.abs(u_pred[k, :, :] - u_true[k, :, :]), cmap='jet')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
